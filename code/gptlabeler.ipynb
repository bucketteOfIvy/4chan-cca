{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre><b>Author:</b> Ashlynn Wimer\n",
    "<b>Date:</b>3/4/2024</pre>\n",
    "\n",
    "This script was where I experimented with chatgpt as a labeling opion. In it, I fine tune a GPT model, test the performance of the fine tuned and untuned GPT at labeling data, before concluding (incorrectly due to a lack of knowledge of daily request limits) that GPT was the way forward for my data classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jsonlines as jsonl\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "import os\n",
    "\n",
    "import HelperChan\n",
    "import GPTHelper\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by acquiring and formatting our data to be used for fine tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in labeled posts\n",
    "labeled_posts = pd.concat(\n",
    "    [\n",
    "        pd.read_csv('../data/first_pass_labels.csv', index_col='Unnamed: 0'),\n",
    "        pd.read_csv('../data/lgbt_week_2_classified.csv', index_col='Unnamed: 0'),\n",
    "        pd.read_csv('../data/lgbt_week_3_classified.csv', index_col='Unnamed: 0')\n",
    "    ],\n",
    "    ignore_index=True\n",
    ").drop_duplicates('id')\n",
    "\n",
    "# Read in all posts to allow for backref\n",
    "all_posts = pd.concat(\n",
    "    [\n",
    "        pd.read_csv('../data/lgbt_week_1.csv'), pd.read_csv('../data/lgbt_week_2.csv'), pd.read_csv('../data/lgbt_week_3.csv')\n",
    "    ], ignore_index=True\n",
    ").drop_duplicates('id')\n",
    "\n",
    "with warnings.catch_warnings(action=\"ignore\"):\n",
    "    # Backref!!\n",
    "    labeled_posts['backref'] = labeled_posts['content'].apply(lambda x: HelperChan.content_with_back_reference(str(x), all_posts))\n",
    "\n",
    "# Recommended lower bound for significant performance improvement according to OpenAI\n",
    "train = labeled_posts.sample(n=50)\n",
    "test = labeled_posts.drop(index=train.index)\n",
    "\n",
    "messages = GPTHelper.create_example_messages(train, content_col='backref')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following sections contain the code I used to create and test a fine-tuned model to compare against base GPT3.5. Any commented out code is code that I do not want to risk running twice on accident. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write our messages to a jsonl\n",
    "# with jsonl.open('../data/fine_tuning/output.jsonl', mode='w') as writer:\n",
    "#     for message in messages:\n",
    "#         writer.write(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ['OPENAI_API_KEY2']\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=openai.api_key.strip()\n",
    ")\n",
    "\n",
    "# client.files.create(\n",
    "#     file=open('../data/fine_tuning/output.jsonl', 'rb'),\n",
    "#     purpose='fine-tune'\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code chunk was used to generate the fine tuning job. However, I *really* don't want to risk re-running the job, so it's commented out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.fine_tuning.jobs.create(\n",
    "#      training_file='file-gT3eiC36253G1jdgP8b2I4GM',\n",
    "#      model='gpt-3.5-turbo-0125',\n",
    "#      hyperparameters={\n",
    "#          'n_epochs':3\n",
    "#      }\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now get both base GPT and tuned GPT to label our posts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt_messages(posts, content_col='content', system_role=None):\n",
    "    '''\n",
    "    Given a dataframe of 4chan posts with content in their content_col,\n",
    "    creates prompt messages for the posts.\n",
    "\n",
    "    Inputs:\n",
    "      posts (DataFrame): posts\n",
    "      content_col (str): name of the column containing content. Defaults to 'content'\n",
    "      system_role (str): name of the system_role, uses a prompt for classifiyn g4chan posts if None. Defautls None.\n",
    "\n",
    "    Returns: list of prompt messages for GPT. \n",
    "    '''\n",
    "\n",
    "    messages = []\n",
    "    system_role = 'You are a classifier which reads the raw content of posts from 4chan\\'s /lgbt/ board, and says whether or not they discuss trans people or trans-related topics. If the post is about trans people, respond \"Yes\". Otherwise, respond \"No\".'    \n",
    "    for post in posts[content_col]:\n",
    "\n",
    "        user_prompt = \\\n",
    "        f'''\n",
    "        Does the following message discuss trans people or trans-related topics? Yes or No.\n",
    "        \n",
    "        MESSAGE: {post}\n",
    "        '''\n",
    "\n",
    "        message = \\\n",
    "            [\n",
    "                {'role': 'system', 'content':system_role},\n",
    "                {'role': 'user', 'content':user_prompt}\n",
    "            ]\n",
    "        \n",
    "        messages.append(message)\n",
    "    \n",
    "    return messages\n",
    "\n",
    "def call_gpt_on_prompts(client, prompts, model='gpt-3.5-turbo-0125'):\n",
    "    '''\n",
    "    Call GPT on a list of prompts and return a list of responses.\n",
    "    \n",
    "    Inputs:\n",
    "      client (OpenAI): the client to call\n",
    "      prompts (list): list of prompts\n",
    "      model (str): list of dictionary prompts.\n",
    "\n",
    "    Returns: list of completion messages\n",
    "    '''\n",
    "    responses = []\n",
    "    for message in prompts:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=message\n",
    "        )\n",
    "        responses.append(response.choices[0].message.content)\n",
    "    \n",
    "    return responses\n",
    "\n",
    "def call_gpt_on_prompts_with_saves(client, prompts, dataframe, save_loc, \n",
    "                                   save_col='gptlabels', model='gpt-3.5-turbo-0125', \n",
    "                                   n_splits=10):\n",
    "    '''\n",
    "    Calls GPT on prompts and gets responses, but actually saves its\n",
    "    progress as it proceeds.\n",
    "\n",
    "    Inputs: \n",
    "      client (OpenAI): OpenAI client.\n",
    "      prompts (list): list of prompts for OpenAI.\n",
    "      dataframe (DataFrame): DataFrame outputs should be saved to.\n",
    "      save_loc (str): string location of where this function should save\n",
    "        its outputs to.\n",
    "      save_col (str): string name of the desired column to save to.\n",
    "      model (str): name of model to use.\n",
    "      save_rate (int): how many promts should be completed between saves.\n",
    "\n",
    "    Returns: None. Saves resultant dataframe to save_loc\n",
    "    '''\n",
    "\n",
    "    assert len(dataframe) == len(prompts), 'Prompts and batches are mismatched.'\n",
    "\n",
    "    df_batches = np.array_split(dataframe, n_splits)\n",
    "    prompts_batches = np.split(np.array(prompts), n_splits)\n",
    "    prompts_batches = [prompt_batch.tolist() for prompt_batch in prompts_batches]\n",
    "\n",
    "    attached_dfs = []\n",
    "    for prompts, batch in zip(prompts_batches, df_batches):\n",
    "        \n",
    "        # Get and attach prompts\n",
    "        resps = call_gpt_on_prompts(client, prompts, model)\n",
    "        batch[save_col] = resps\n",
    "\n",
    "        # Save\n",
    "        attached_dfs.append(batch.copy())\n",
    "        pd.concat(attached_dfs, ignore_index=True).to_csv(save_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = create_prompt_messages(test, content_col='backref')\n",
    "\n",
    "#untuned_resps = call_gpt_on_prompts(client, prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save our work in case we're cursed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test['untuned'] = untuned_resps\n",
    "\n",
    "#test.to_csv('../data/test_with_untuned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuned_resps = call_gpt_on_prompts(client, prompts, model='ft:gpt-3.5-turbo-0125:personal::8zCxjHNl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test['tuned'] = tuned_resps\n",
    "\n",
    "#test.to_csv('../data/test_with_both.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/test_with_both.csv', index_col='Unnamed: 0')\n",
    "test['untuned'] = test['untuned'].apply(lambda x: 1 if x=='Yes' else 0)\n",
    "test['tuned'] = test['tuned'].apply(lambda x: 1 if x=='Yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>content</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>refs</th>\n",
       "      <th>urls</th>\n",
       "      <th>classification</th>\n",
       "      <th>backref</th>\n",
       "      <th>untuned</th>\n",
       "      <th>tuned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>post suifuel</td>\n",
       "      <td>34577209</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>2/7/2024</td>\n",
       "      <td>19:35:44</td>\n",
       "      <td>&gt;&gt;34571853If they stop after the first one, th...</td>\n",
       "      <td>\\r\\nIf they stop after the first one, they loo...</td>\n",
       "      <td>['&gt;&gt;34571853']</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;ref&gt;'How do these plastic surgery addicts loo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34604558</td>\n",
       "      <td>34605860</td>\n",
       "      <td>)*Kassandra of Ellaphae|PSO2</td>\n",
       "      <td>2/10/2024</td>\n",
       "      <td>2:34:13</td>\n",
       "      <td>&gt;&gt;34605630thought someone might like that :3i ...</td>\n",
       "      <td>\\r\\nthought someone might like that :3i dont n...</td>\n",
       "      <td>['&gt;&gt;34605630']</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;ref&gt;'&gt;&gt;34605584that’s pretty hot actually'&lt;/r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34606802</td>\n",
       "      <td>34611390</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>02/10/24</td>\n",
       "      <td>15:09:03</td>\n",
       "      <td>&gt;&gt;34606802&gt;Is being a transbian bad?yesthey're...</td>\n",
       "      <td>\\r\\n&gt;Is being a transbian bad?yesthey're all d...</td>\n",
       "      <td>['&gt;&gt;34606802']</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;ref&gt;\"Is being a transbian bad? Whenever I tel...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/chasergen/ black hole edition</td>\n",
       "      <td>34593140</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>2/9/2024</td>\n",
       "      <td>2:23:20</td>\n",
       "      <td>why do deranged transbians not stick to their ...</td>\n",
       "      <td>why do deranged transbians not stick to their ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "      <td>why do deranged transbians not stick to their ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/mtfg/ huh?</td>\n",
       "      <td>34557268</td>\n",
       "      <td>A.G.P. pilot \"naz\" Nullifier(...)</td>\n",
       "      <td>2/6/2024</td>\n",
       "      <td>1:44:31</td>\n",
       "      <td>heathers really resonates with mehttps://youtu...</td>\n",
       "      <td>heathers really resonates with mehttps://youtu...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['/watch?v=LIHPNqYiPSMalmost']</td>\n",
       "      <td>0</td>\n",
       "      <td>heathers really resonates with mehttps://youtu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          subject        id  \\\n",
       "0                    post suifuel  34577209   \n",
       "1                        34604558  34605860   \n",
       "2                        34606802  34611390   \n",
       "3  /chasergen/ black hole edition  34593140   \n",
       "4                     /mtfg/ huh?  34557268   \n",
       "\n",
       "                              author       date      time  \\\n",
       "0                          Anonymous   2/7/2024  19:35:44   \n",
       "1       )*Kassandra of Ellaphae|PSO2  2/10/2024   2:34:13   \n",
       "2                          Anonymous   02/10/24  15:09:03   \n",
       "3                          Anonymous   2/9/2024   2:23:20   \n",
       "4  A.G.P. pilot \"naz\" Nullifier(...)   2/6/2024   1:44:31   \n",
       "\n",
       "                                             content  \\\n",
       "0  >>34571853If they stop after the first one, th...   \n",
       "1  >>34605630thought someone might like that :3i ...   \n",
       "2  >>34606802>Is being a transbian bad?yesthey're...   \n",
       "3  why do deranged transbians not stick to their ...   \n",
       "4  heathers really resonates with mehttps://youtu...   \n",
       "\n",
       "                                       clean_content            refs  \\\n",
       "0  \\r\\nIf they stop after the first one, they loo...  ['>>34571853']   \n",
       "1  \\r\\nthought someone might like that :3i dont n...  ['>>34605630']   \n",
       "2  \\r\\n>Is being a transbian bad?yesthey're all d...  ['>>34606802']   \n",
       "3  why do deranged transbians not stick to their ...              []   \n",
       "4  heathers really resonates with mehttps://youtu...              []   \n",
       "\n",
       "                             urls  classification  \\\n",
       "0                              []               1   \n",
       "1                              []               0   \n",
       "2                              []               1   \n",
       "3                              []               1   \n",
       "4  ['/watch?v=LIHPNqYiPSMalmost']               0   \n",
       "\n",
       "                                             backref  untuned  tuned  \n",
       "0  <ref>'How do these plastic surgery addicts loo...        1      1  \n",
       "1  <ref>'>>34605584that’s pretty hot actually'</r...        0      0  \n",
       "2  <ref>\"Is being a transbian bad? Whenever I tel...        1      1  \n",
       "3  why do deranged transbians not stick to their ...        1      1  \n",
       "4  heathers really resonates with mehttps://youtu...        0      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.88, 0.8622222222222222)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_accuracy = (sum(test['tuned'] == test['classification'])) / len(test)\n",
    "untuned_accuracy = (sum(test['untuned'] == test['classification'])) / len(test)\n",
    "\n",
    "tuned_accuracy, untuned_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89       244\n",
      "           1       0.90      0.83      0.86       206\n",
      "\n",
      "    accuracy                           0.88       450\n",
      "   macro avg       0.88      0.88      0.88       450\n",
      "weighted avg       0.88      0.88      0.88       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test['classification'], test['tuned'], labels=[0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       244\n",
      "           1       0.89      0.80      0.84       206\n",
      "\n",
      "    accuracy                           0.86       450\n",
      "   macro avg       0.87      0.86      0.86       450\n",
      "weighted avg       0.86      0.86      0.86       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test['classification'], test['untuned'], labels=[0,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is.. notably better than a supervised model performs. \n",
    "\n",
    "Guess that means I'm using GPT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "  0%|          | 0/186635 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 186635/186635 [00:26<00:00, 7033.27it/s]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "with warnings.catch_warnings(action=\"ignore\"):\n",
    "    all_posts['backref'] = all_posts['content'].progress_apply(\n",
    "        lambda x: HelperChan.content_with_back_reference(str(x), labeled_posts))\n",
    "\n",
    "to_label = all_posts.sample(n=4500).reset_index(drop=True)\n",
    "\n",
    "prompts = create_prompt_messages(to_label, content_col='backref')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "call_gpt_on_prompts_with_saves(client, prompts=prompts, dataframe=to_label, \n",
    "                               save_loc='../data/gpt_labeled.csv', model='gpt-3.5-turbo-0125', \n",
    "                               n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186635, 4500, 182135)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled = pd.read_csv('../data/gpt_labeled.csv', index_col='Unnamed: 0')\n",
    "\n",
    "already_labeled = all_posts['id'].isin(labeled['id'])\n",
    "\n",
    "subset = all_posts[~already_labeled]\n",
    "\n",
    "len(all_posts), len(labeled), len(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_label = subset.sample(n=4500).reset_index(drop=True)\n",
    "\n",
    "prompts = create_prompt_messages(to_label, content_col='backref')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "call_gpt_on_prompts_with_saves(client, prompts=prompts, dataframe=to_label, \n",
    "                               save_loc='../data/gpt_labeled_2.csv', model='gpt-3.5-turbo-0125', \n",
    "                               n_splits=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
